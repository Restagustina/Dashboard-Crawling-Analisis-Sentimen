# crawling.py
import time
import random
from datetime import datetime
from urllib.parse import urlsplit, parse_qsl
import streamlit as st
from serpapi import GoogleSearch
from sentiment import save_reviews_to_supabase, update_sentiment_in_supabase

# --- GOOGLE MAPS ---
def run_serpapi_gmaps_paginated(place_id=None, api_key=None, max_reviews=15):
    # kalau tidak ada argumen, fallback ke secrets
    place_id = place_id or st.secrets.get("PLACE_ID")
    api_key = api_key or st.secrets.get("SERPAPI_KEY")

    if not place_id or not api_key:
        print("[ERROR] PLACE_ID atau SERPAPI_KEY tidak ditemukan!")
        return []

    print(f"[INFO] Mulai crawling Google Maps dengan place_id={place_id}")
    params = {
        "engine": "google_maps_reviews",
        "data_id": place_id,
        "hl": "id",
        "api_key": api_key
    }

    search = GoogleSearch(params)
    all_reviews = []

    while True:
        results = search.get_dict()
        print(f"[DEBUG] Keys di results: {list(results.keys()) if results else 'None'}")
        if not results or "error" in results:
            print(f"[WARNING] Error atau data kosong dari SerpApi: {results.get('error') if results else 'No data'}")
            break

        review_results = results.get("reviews", [])
        print(f"[DEBUG] Jumlah review batch ini: {len(review_results)}")
        all_reviews.extend(review_results)

        serpapi_pagination = results.get("serpapi_pagination", {})
        next_url = serpapi_pagination.get("next")

        if next_url and len(all_reviews) < max_reviews:
            search.params_dict.update(dict(parse_qsl(urlsplit(next_url).query)))
            print(f"[INFO] Lanjut ke halaman berikutnya, total review saat ini: {len(all_reviews)}")
        else:
            break

    print(f"[INFO] Total review yang dikumpulkan: {len(all_reviews[:max_reviews])}")

    # Bersihkan hasil
    cleaned_reviews = [
        {
            "review_id": rev.get("review_id"),
            "username": rev.get("user", {}).get("name") if isinstance(rev.get("user"), dict) else rev.get("user"),
            "comment_text": rev.get("snippet"),
            "rating": rev.get("rating"),
            "created_at": rev.get("date")
        }
        for rev in all_reviews[:max_reviews]
    ]

    return cleaned_reviews

# --- GOOGLE PLAY STORE ---
try:
    from google_play_scraper import reviews as playstore_reviews
except ImportError:
    playstore_reviews = None
    print("âš ï¸ Module google_play_scraper belum terinstall, Play Store scraping nonaktif.")


def get_playstore_reviews_app(app_package_name, count=10, max_retries=3, max_loops=5):
    """Scraping review Play Store pakai google_play_scraper."""
    if playstore_reviews is None:
        return []

    all_reviews = []
    cursor = None
    loops = 0

    try:
        while loops < max_loops:
            loops += 1
            for attempt in range(1, max_retries + 1):
                try:
                    result, cursor = playstore_reviews(
                        app_package_name,
                        lang='id',
                        count=count,
                        continuation_token=cursor
                    )
                    print(f"DEBUG: batch {loops}, cursor={cursor}")
                    time.sleep(random.uniform(1.5, 3.0))
                    break
                except Exception as e:
                    print(f"âš ï¸ Error scraping Play Store (attempt {attempt}): {e}")
                    if attempt == max_retries:
                        return all_reviews
                    time.sleep(random.uniform(2, 5))

            for rev in result:
                all_reviews.append({
                    "review_id": str(rev.get("reviewId")),
                    "username": rev.get("userName"),
                    "comment_text": rev.get("content"),
                    "rating": rev.get("score"),
                    "created_at": rev.get("at").isoformat() if isinstance(rev.get("at"), datetime) else None
                })
            if cursor is None:
                break
    except Exception as e:
        print(f"âš ï¸ Fatal error scraping Play Store: {e}")

    return all_reviews

# --- FUNGSIONAL UTAMA ---
def run_crawling_and_analysis(place_id=None, app_package_name=None, max_reviews=15, status_placeholder=None):
    if not place_id:
        if status_placeholder:
            status_placeholder.error("âŒ place_id Google Maps tidak diberikan.")
        return

    if status_placeholder:
        status_placeholder.text("ðŸ“Œ Crawling Google Maps via SerpApi...")

    try:
        gmaps_results = run_serpapi_gmaps_paginated(place_id, max_reviews)
        print(f"[INFO] gmaps_results: {len(gmaps_results) if gmaps_results else 0} review ditemukan")

        # --- Cek hasil crawl ---
        if not gmaps_results:
            if status_placeholder:
                status_placeholder.error("âš ï¸ Tidak ada review Google Maps yang ditemukan. Cek API key / place_id.")
            return  # STOP di sini kalau kosong

        # --- Simpan ke Supabase ---
        if status_placeholder:
            status_placeholder.text(f"Berhasil ambil {len(gmaps_results)} review Google Maps, menyimpan ke Supabase...")

        saved = save_reviews_to_supabase(gmaps_results, "gmaps")

        if saved:
            if status_placeholder:
                status_placeholder.success(f"{len(gmaps_results)} review Google Maps berhasil disimpan ke Supabase.")
        else:
            if status_placeholder:
                status_placeholder.error("âš ï¸ Beberapa review Google Maps gagal disimpan ke Supabase, cek log.")

        # --- Lanjut ke analisis sentimen ---
        if status_placeholder:
            status_placeholder.text("ðŸ§  Analisis sentimen dimulai...")

        analyzed = update_sentiment_in_supabase("gmaps")

        if status_placeholder:
            status_placeholder.success(f"âœ… Analisis sentimen selesai. {analyzed} review dianalisis.")

    except Exception as e:
        msg = f"âš ï¸ Gagal crawling Google Maps via SerpApi: {e}"
        if status_placeholder:
            status_placeholder.error(msg)
        print(msg)

    # --- Play Store ---
    if app_package_name:
        if status_placeholder:
            status_placeholder.text("ðŸ“Œ Crawling Play Store...")
        ps_reviews = get_playstore_reviews_app(app_package_name, count=max_reviews)
        print(f"[INFO] ps_reviews: {len(ps_reviews)} review ditemukan")
        if ps_reviews:
            if status_placeholder:
                status_placeholder.text(f"Berhasil ambil {len(ps_reviews)} review Play Store, menyimpan ke Supabase...")
            try:
                saved = save_reviews_to_supabase(ps_reviews, "playstore")
                if saved:
                    if status_placeholder:
                        status_placeholder.success(f"{len(ps_reviews)} review Play Store berhasil disimpan ke Supabase.")
                else:
                    if status_placeholder:
                        status_placeholder.error("âš ï¸ Beberapa review Play Store gagal disimpan ke Supabase, cek log.")
            except Exception as e:
                error_msg = f"âš ï¸ Gagal simpan review Play Store ke Supabase: {e}"
                print(error_msg)
                if status_placeholder:
                    status_placeholder.error(error_msg)
        else:
            if status_placeholder:
                status_placeholder.warning("âš ï¸ Tidak ada review Play Store ditemukan.")

    # --- Analisis Sentimen ---
    if place_id or app_package_name:
        if status_placeholder:
            status_placeholder.text("ðŸ“Œ Memulai update sentimen...")
        updated_count = update_sentiment_in_supabase()
        if status_placeholder:
            status_placeholder.success(f"âœ… Analisis sentimen selesai. {updated_count} review dianalisis.")
    else:
        if status_placeholder:
            status_placeholder.warning("âš ï¸ Tidak ada sumber data yang dipilih, proses dibatalkan.")
